{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVgELqi73i5H",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b71b12-89da-4d52-e9f3-451b71b043a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.12.0 in /usr/local/lib/python3.11/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.71.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.13.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.13.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "Requirement already satisfied: tensorflow-model-optimization in /usr/local/lib/python3.11/dist-packages (0.8.0)\n",
            "Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (0.1.9)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.23.5)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.17.0)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (25.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (1.14.1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install tensorflow==2.12.0\n",
        "!pip install tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make sure it is 2.12.0 before doing any work\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "gFGVz90awQO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed128e42-7730-4384-e85e-46020ca1bef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: navigate to a folder in my google drive My Drive > data > fall_data\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/Data/\n",
        "!pwd\n"
      ],
      "metadata": {
        "id": "XFbhcwHbwW8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67a26a2d-6d90-4a3a-ec0c-bd7a02bee352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/Data\n",
            "/content/drive/My Drive/Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the four CSV files into dataframes without the index\n",
        "df_sitting = pd.read_csv('sitting_data.csv', index_col=False)\n",
        "df_standing = pd.read_csv('standing_data.csv', index_col=False)\n",
        "df_walking = pd.read_csv('walking_data.csv', index_col=False)\n",
        "df_falling = pd.read_csv('falling_data.csv', index_col=False)\n",
        "\n",
        "# Specify the columns that contain gyro and accel data\n",
        "gyro_accel_columns = ['Gyro_X', 'Gyro_Y', 'Gyro_Z', 'Accel_X', 'Accel_Y', 'Accel_Z']  # Replace with actual column names\n",
        "\n"
      ],
      "metadata": {
        "id": "GAR5rIdgvaUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries (add libraries you need here)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout,Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "r6vmcHQlxNCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create a sliding window dataframe for specific columns\n",
        "def create_sliding_window_df(df, columns, window_size):\n",
        "    sliding_window_data = []\n",
        "    for i in range(len(df) - window_size + 1):\n",
        "        window = df[columns].iloc[i:i + window_size].values.flatten()\n",
        "        sliding_window_data.append(window)\n",
        "    return pd.DataFrame(sliding_window_data)"
      ],
      "metadata": {
        "id": "Q-ggJhgevaFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your window_size\n",
        "window_size = 15\n",
        "\n",
        "# Create new dataframes with sliding windows for gyro and accel data\n",
        "df_sitting_windowed = create_sliding_window_df(df_sitting, gyro_accel_columns,window_size)\n",
        "df_standing_windowed = create_sliding_window_df(df_standing, gyro_accel_columns,window_size)\n",
        "df_walking_windowed = create_sliding_window_df(df_walking, gyro_accel_columns,window_size)\n",
        "df_falling_windowed = create_sliding_window_df(df_falling, gyro_accel_columns,window_size)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_sitting_windowed = pd.DataFrame(scaler.fit_transform(df_sitting_windowed), columns=df_sitting_windowed.columns)\n",
        "df_standing_windowed = pd.DataFrame(scaler.fit_transform(df_standing_windowed), columns=df_standing_windowed.columns)\n",
        "df_walking_windowed = pd.DataFrame(scaler.fit_transform(df_walking_windowed), columns=df_walking_windowed.columns)\n",
        "df_falling_windowed = pd.DataFrame(scaler.fit_transform(df_falling_windowed), columns=df_falling_windowed.columns)\n",
        "\n",
        "# Add labels to the windowed dataframes\n",
        "df_sitting_windowed['Label'] = 0\n",
        "df_standing_windowed['Label'] = 1\n",
        "df_walking_windowed['Label'] = 2\n",
        "df_falling_windowed['Label'] = 3"
      ],
      "metadata": {
        "id": "r4nNPzK1v2ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATAFRAME\n",
        "# Concatenate all windowed dataframes into one large dataframe X\n",
        "X_df = pd.concat([df_sitting_windowed, df_standing_windowed, df_walking_windowed, df_falling_windowed], ignore_index=True)\n",
        "\n",
        "# Randomize the order of the X data\n",
        "X_df = shuffle(X_df, random_state=42)\n",
        "# Separate the labels into a dataframe y\n",
        "y_df = X_df.pop('Label')\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded_df = label_encoder.fit_transform(y_df)\n",
        "y_categorical_df = to_categorical(y_encoded_df, num_classes=4)  # Ensure 4 classes for one-hot encoding\n"
      ],
      "metadata": {
        "id": "sK0kOvc1vlmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten, Input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow_model_optimization.quantization.keras import quantize_annotate_layer\n",
        "from tensorflow_model_optimization.quantization.keras import quantize_annotate_model\n",
        "from tensorflow_model_optimization.quantization.keras import quantize_scope\n",
        "from tensorflow_model_optimization.quantization.keras import quantize_apply\n"
      ],
      "metadata": {
        "id": "vXnmHFemwEqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATAFRAME: DO NOT EXECUTE THIS YET\n",
        "# Reshape X to be 3D [samples, window size, features]\n",
        "n_features = 6 #X_array.shape[1] #features\n",
        "X_reshape_df = X_df.to_numpy().reshape(X_df.shape[0], window_size, n_features) #Reshape to 3D array\n",
        "\n",
        "\n",
        "# Split the data into training, testing, and validation sets\n",
        "X_train_df, X_temp_df, y_train_df, y_temp_df = train_test_split(X_reshape_df, y_categorical_df, test_size=0.4, random_state=42)\n",
        "X_test_df, X_val_df, y_test_df, y_val_df = train_test_split(X_temp_df, y_temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "print(\"Data has been successfully split into training, testing, and validation sets.\")\n",
        "print(f\"Training set size: {len(X_train_df)}\")\n",
        "print(f\"Testing set size: {len(X_test_df)}\")\n",
        "print(f\"Validation set size: {len(X_val_df)}\")\n",
        "\n",
        "input_shape = (window_size,n_features)  # Example: 10 features\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential()\n",
        "model.add(Input(shape=input_shape))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4, activation='softmax'))  # Assuming 4 classes: sitting, standing, walking, falling\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_df = model.fit(X_train_df, y_train_df, epochs=10, batch_size=32, validation_data=(X_val_df, y_val_df))\n",
        "\n",
        "# Evaluate the model\n",
        "loss_df, accuracy_df = model.evaluate(X_test_df, y_test_df)\n",
        "print(f'Test Accuracy: {accuracy_df:.2f}')"
      ],
      "metadata": {
        "id": "QJSQElrAXzCO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61688c3-860a-4592-bf4b-2aaa0a078956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been successfully split into training, testing, and validation sets.\n",
            "Training set size: 6686\n",
            "Testing set size: 2229\n",
            "Validation set size: 2229\n",
            "Epoch 1/10\n",
            "209/209 [==============================] - 4s 8ms/step - loss: 1.2776 - accuracy: 0.4233 - val_loss: 0.9922 - val_accuracy: 0.6528\n",
            "Epoch 2/10\n",
            "209/209 [==============================] - 2s 7ms/step - loss: 0.9429 - accuracy: 0.6339 - val_loss: 0.6427 - val_accuracy: 0.7730\n",
            "Epoch 3/10\n",
            "209/209 [==============================] - 1s 7ms/step - loss: 0.7097 - accuracy: 0.7438 - val_loss: 0.4554 - val_accuracy: 0.8430\n",
            "Epoch 4/10\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 0.5300 - accuracy: 0.8095 - val_loss: 0.3082 - val_accuracy: 0.9022\n",
            "Epoch 5/10\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 0.4241 - accuracy: 0.8521 - val_loss: 0.2262 - val_accuracy: 0.9197\n",
            "Epoch 6/10\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 0.3233 - accuracy: 0.8847 - val_loss: 0.1715 - val_accuracy: 0.9511\n",
            "Epoch 7/10\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 0.2611 - accuracy: 0.9094 - val_loss: 0.1230 - val_accuracy: 0.9641\n",
            "Epoch 8/10\n",
            "209/209 [==============================] - 1s 5ms/step - loss: 0.2082 - accuracy: 0.9270 - val_loss: 0.0987 - val_accuracy: 0.9672\n",
            "Epoch 9/10\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 0.1649 - accuracy: 0.9441 - val_loss: 0.0855 - val_accuracy: 0.9713\n",
            "Epoch 10/10\n",
            "209/209 [==============================] - 1s 4ms/step - loss: 0.1362 - accuracy: 0.9557 - val_loss: 0.0615 - val_accuracy: 0.9807\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.9744\n",
            "Test Accuracy: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set-up\n",
        "model = model\n",
        "model_file_name = 'Check_Point.tflite' #change the name for your model\n",
        "\n",
        "# Convert the model to TensorFlow Lite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS,  # Built-in operations - ReLU, Conv2D, MaxPool, Dense, etc...\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS     # Select TensorFlow operations - maybe for LSTM/RNN layers\n",
        "]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT] # See below\n",
        "converter.inference_input_type = tf.float32\n",
        "converter.inference_output_type = tf.float32\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TensorFlow Lite model to a file\n",
        "with open(model_file_name, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"Model converted to TensorFlow Lite and saved as \", model_file_name)\n"
      ],
      "metadata": {
        "id": "JHsWJWpOwJJS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef701f65-b4ae-4272-8121-4c1656eca56d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model converted to TensorFlow Lite and saved as  Check_Point.tflite\n"
          ]
        }
      ]
    }
  ]
}